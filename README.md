
# ğŸ™ï¸ VoiceBot â€” AI-Powered Conversational Agent

**VoiceBot** is an intelligent voice-enabled chatbot that leverages the power of **LangChain**, **GROQ API**, and **LLaMA LLM** to answer any natural language question. The bot uses speech-to-text (STT), processes the query with a large language model, and then responds with human-like speech using text-to-speech (TTS).

---

## ğŸš€ Features

* ğŸ”— **LangChain Framework**: Manages prompts, chains, tools, and memory for better context-aware conversations.
* ğŸ§  **GROQ + LLaMA LLM**: Fast and efficient LLM inference using Metaâ€™s LLaMA models on GROQ's infrastructure.
* ğŸ—£ï¸ **Speech-to-Text (STT)**: Converts userâ€™s voice input to text using tools like OpenAI Whisper or Google Speech API.
* ğŸ”Š **Text-to-Speech (TTS)**: Responds with natural-sounding voice using tools like gTTS or pyttsx3.
* ğŸŒ **Web-Based Interface**: Simple web app for seamless interaction with the bot.

---

## ğŸ§° Tech Stack

* **LangChain**
* **GROQ API (LLaMA Model)**
* **Whisper / Google Speech Recognition** (STT)
* **gTTS / pyttsx3** (TTS)
* **Flask / Streamlit / Gradio** (Frontend Interface)
* **Python 3.10+**

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/yourusername/voicebot-groq-llama.git
cd voicebot-groq-llama
pip install -r requirements.txt
```

---

## ğŸ”‘ Environment Variables

Create a `.env` file in the root directory:

```
GROQ_API_KEY=your_groq_api_key_here
LANGCHAIN_API_KEY=your_optional_langchain_key
```

---

## ğŸ§  How It Works

1. **User speaks** into the microphone.
2. **Speech is transcribed** to text via Whisper or Google STT.
3. **LangChain** constructs a prompt and sends it to **GROQ API** using the **LLaMA model**.
4. The **LLM response** is received and converted to speech via **TTS**.
5. The bot **responds vocally** to the user.

---

## ğŸ§ª Run the App

```bash
python app.py
```

Or if you're using Streamlit:

```bash
streamlit run app.py
```

---

## ğŸ“ Project Structure

```
voicebot/
â”‚
â”œâ”€â”€ app.py                # Main application logic
â”œâ”€â”€ agents/               # LangChain agent setup
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ stt.py            # Speech-to-text logic
â”‚   â”œâ”€â”€ tts.py            # Text-to-speech logic
â”‚   â””â”€â”€ llama_chain.py    # LangChain + GROQ setup
â”œâ”€â”€ templates/            # (Optional) HTML for web interface
â”œâ”€â”€ static/               # JS/CSS files
â”œâ”€â”€ .env                  # Environment variables
â””â”€â”€ requirements.txt
```

---

## ğŸ§  Prompt Engineering with LangChain

The app uses LangChainâ€™s LLM wrappers with a custom prompt template that routes all queries through the LLaMA model via the GROQ endpoint:

```python
llm = ChatGroq(
    model="llama3-8b-8192",
    api_key=os.getenv("GROQ_API_KEY")
)
```

---



---

## ğŸ›¡ï¸ License

This project is licensed under the MIT License.

---

## ğŸ™Œ Acknowledgements

* [LangChain](https://github.com/langchain-ai/langchain)
* [GROQ](https://groq.com/)
* [Meta LLaMA](https://ai.meta.com/llama/)
* [OpenAI Whisper](https://github.com/openai/whisper)
* [gTTS](https://pypi.org/project/gTTS/)
* [Gradio / Streamlit](https://www.gradio.app/)

---




